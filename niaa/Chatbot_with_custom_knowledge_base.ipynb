{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sherw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import llama_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UelAqQgk_yIt"
      },
      "outputs": [],
      "source": [
        "from llama_index import SimpleDirectoryReader, GPTVectorStoreIndex, LLMPredictor, PromptHelper, ServiceContext\n",
        "from langchain import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import sys\n",
        "import os\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def construct_index(directory_path):\n",
        "    # set maximum input size\n",
        "    max_input_size = 4096\n",
        "    num_outputs = 512\n",
        "    max_chunk_overlap = 1\n",
        "    chunk_size_limit = 600\n",
        "\n",
        "    # define prompt helper\n",
        "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
        "\n",
        "    # define LLM\n",
        "    llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0.9, model_name=\"gpt-3.5-turbo\"))\n",
        " \n",
        "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
        "    \n",
        "    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n",
        "    index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)\n",
        "\n",
        "    index.storage_context.persist(persist_dir=\"AI\")\n",
        "\n",
        "    return index\n",
        "\n",
        "def ask_ai():\n",
        "    from llama_index import StorageContext, load_index_from_storage\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=\"AI\")\n",
        "    index = load_index_from_storage(storage_context)\n",
        "\n",
        "    while True:\n",
        "        query_engine = index.as_query_engine() \n",
        "        query = input(\"What do you want to ask? \")\n",
        "        response = query_engine.query(query)\n",
        "        display(Markdown(f\"Response: <b>{response.response}</b>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RoJHE4fsAT3w"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCYTE2EqBB7O",
        "outputId": "20131d67-aa35-4ebb-9494-5cd7f92dea26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<llama_index.indices.vector_store.base.GPTVectorStoreIndex at 0x2cd422df550>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "construct_index(\"Data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "s_uwsPGEIGsb",
        "outputId": "c0fd9ed7-3d5d-4a82-9e49-231a61603a64"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Response: <b>\n",
              "Answer: Sherwin is not mentioned in the context information provided.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Response: <b>\n",
              "Duraipandian is not mentioned in the context information provided.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Response: <b>\n",
              "Answer: Dr. N. Duraipandian. M.E., Ph.D., is the Principal of Saveetha Engineering College.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Response: <b>\n",
              "The Department of Artificial Intelligence was established in the year 2020 with an intake of 60 students. It is a four-year full-time undergraduate program recognized by the All India Council for Technical Education (AICTE). The department has 2 well-equipped laboratories with higher configuration systems along with a smartboard available in each laboratory to give the best to the students. All classrooms are well furnished, air-conditioned, with a smart board facility. The department also provides exclusive training for competitive exams such as GRE,GMAT,CAT,MAT,Toefl,IES/ GATE etc.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Response: <b>\n",
              "Saveetha Engineering College (SEC) is a premier engineering college located in Chennai, India. It is affiliated to Anna University and is approved by the All India Council for Technical Education (AICTE). The college offers a wide range of courses in engineering, technology, management, and other disciplines. It has a strong focus on research and development, and has a number of research centers and laboratories. The college also has a strong emphasis on industry-academia collaboration, and has established partnerships with leading companies in the industry. The college has a strong commitment to providing quality education and has a dedicated faculty and staff. It also has a number of student clubs and societies, and provides a range of extracurricular activities.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Response: <b>\n",
              "Saveetha Engineering College (SEC) is a leading Engineering College located in Chennai, India, offering a global approach to education and research, with a focus on global perspectives and expertise. SEC offers a wide range of undergraduate, postgraduate and doctoral programs in Engineering. It has a 97% placement rate, 233+ multinational companies visiting the campus, 1302 placement offers, highest CTC of Rs. 34 Lakhs per annum and an average CTC of Rs. 6.15 Lakhs per annum. It also has a 45 acre farm with well-equipped soil science, agriculture metrology and crop husbandry labs, a modern food and agricultural processing laboratory, latest soil and water modeling software, and a centralized on-field irrigation system. The college also provides soft skills training, language and communication, problem solving, aptitude and technical training. All classrooms are equipped with high end smart board facilities with internet connection and 24x7 online learning centre. Saveetha Engineering College is the perfect choice for students looking for a quality education and excellent placement opportunities.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Response: <b>\n",
              "Accenture is a multinational professional services company that provides services in strategy, consulting, digital, technology and operations. It is one of the companies that recruits CSE students from Saveetha Engineering College (SEC).</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Response: <b>\n",
              "Answer: Several companies are currently recruiting AI students, including but not limited to Google, Microsoft, IBM, Amazon, Apple, Facebook, NVIDIA, Intel, Salesforce, and so on.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Response: <b>\n",
              "I am Niaa custom trained ChatGPT model by an AI student.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Response: <b>\n",
              "Answer: Saveetha Engineering College provides hostel facilities for both boys and girls. The hostel is equipped with all modern amenities and provides a safe and secure environment for the students. The hostel has a total capacity of 600 students and is located within the college campus. The hostel provides 24-hour security, CCTV surveillance, Wi-Fi, and other facilities. The hostel also has a cafeteria, gym, and recreation room.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ask_ai()\n",
            "Cell \u001b[1;32mIn[2], line 38\u001b[0m, in \u001b[0;36mask_ai\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m query_engine \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39mas_query_engine() \n\u001b[0;32m     37\u001b[0m query \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWhat do you want to ask? \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m response \u001b[39m=\u001b[39m query_engine\u001b[39m.\u001b[39;49mquery(query)\n\u001b[0;32m     39\u001b[0m display(Markdown(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mResponse: <b>\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mresponse\u001b[39m}\u001b[39;00m\u001b[39m</b>\u001b[39m\u001b[39m\"\u001b[39m))\n",
            "File \u001b[1;32mc:\\Users\\sherw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\query\\base.py:23\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(str_or_query_bundle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m     22\u001b[0m     str_or_query_bundle \u001b[39m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[1;32m---> 23\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query(str_or_query_bundle)\n\u001b[0;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
            "File \u001b[1;32mc:\\Users\\sherw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\query_engine\\retriever_query_engine.py:140\u001b[0m, in \u001b[0;36mRetrieverQueryEngine._query\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m    137\u001b[0m query_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_event_start(CBEventType\u001b[39m.\u001b[39mQUERY)\n\u001b[0;32m    139\u001b[0m retrieve_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_event_start(CBEventType\u001b[39m.\u001b[39mRETRIEVE)\n\u001b[1;32m--> 140\u001b[0m nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retriever\u001b[39m.\u001b[39;49mretrieve(query_bundle)\n\u001b[0;32m    141\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_event_end(\n\u001b[0;32m    142\u001b[0m     CBEventType\u001b[39m.\u001b[39mRETRIEVE, payload\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mnodes\u001b[39m\u001b[39m\"\u001b[39m: nodes}, event_id\u001b[39m=\u001b[39mretrieve_id\n\u001b[0;32m    143\u001b[0m )\n\u001b[0;32m    145\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_synthesizer\u001b[39m.\u001b[39msynthesize(\n\u001b[0;32m    146\u001b[0m     query_bundle\u001b[39m=\u001b[39mquery_bundle,\n\u001b[0;32m    147\u001b[0m     nodes\u001b[39m=\u001b[39mnodes,\n\u001b[0;32m    148\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\sherw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\base_retriever.py:21\u001b[0m, in \u001b[0;36mBaseRetriever.retrieve\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(str_or_query_bundle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m     20\u001b[0m     str_or_query_bundle \u001b[39m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[1;32m---> 21\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retrieve(str_or_query_bundle)\n",
            "File \u001b[1;32mc:\\Users\\sherw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\token_counter\\token_counter.py:78\u001b[0m, in \u001b[0;36mllm_token_counter.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[1;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_llm_predict\u001b[39m(_self: Any, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m     77\u001b[0m     \u001b[39mwith\u001b[39;00m wrapper_logic(_self):\n\u001b[1;32m---> 78\u001b[0m         f_return_val \u001b[39m=\u001b[39m f(_self, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m f_return_val\n",
            "File \u001b[1;32mc:\\Users\\sherw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\vector_store\\retrievers\\retriever.py:70\u001b[0m, in \u001b[0;36mVectorIndexRetriever._retrieve\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39mis_embedding_query:\n\u001b[0;32m     68\u001b[0m     \u001b[39mif\u001b[39;00m query_bundle\u001b[39m.\u001b[39membedding \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m         query_bundle\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m (\n\u001b[1;32m---> 70\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_service_context\u001b[39m.\u001b[39;49membed_model\u001b[39m.\u001b[39;49mget_agg_embedding_from_queries(\n\u001b[0;32m     71\u001b[0m                 query_bundle\u001b[39m.\u001b[39;49membedding_strs\n\u001b[0;32m     72\u001b[0m             )\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     75\u001b[0m query \u001b[39m=\u001b[39m VectorStoreQuery(\n\u001b[0;32m     76\u001b[0m     query_embedding\u001b[39m=\u001b[39mquery_bundle\u001b[39m.\u001b[39membedding,\n\u001b[0;32m     77\u001b[0m     similarity_top_k\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_similarity_top_k,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m     filters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filters,\n\u001b[0;32m     83\u001b[0m )\n\u001b[0;32m     84\u001b[0m query_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39mquery(query, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs)\n",
            "File \u001b[1;32mc:\\Users\\sherw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\embeddings\\base.py:91\u001b[0m, in \u001b[0;36mBaseEmbedding.get_agg_embedding_from_queries\u001b[1;34m(self, queries, agg_fn)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_agg_embedding_from_queries\u001b[39m(\n\u001b[0;32m     86\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     87\u001b[0m     queries: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m     88\u001b[0m     agg_fn: Optional[Callable[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     89\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[0;32m     90\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get aggregated embedding from multiple queries.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m     query_embeddings \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_query_embedding(query) \u001b[39mfor\u001b[39;49;00m query \u001b[39min\u001b[39;49;00m queries]\n\u001b[0;32m     92\u001b[0m     agg_fn \u001b[39m=\u001b[39m agg_fn \u001b[39mor\u001b[39;00m mean_agg\n\u001b[0;32m     93\u001b[0m     \u001b[39mreturn\u001b[39;00m agg_fn(query_embeddings)\n",
            "File \u001b[1;32mc:\\Users\\sherw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\embeddings\\base.py:91\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_agg_embedding_from_queries\u001b[39m(\n\u001b[0;32m     86\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     87\u001b[0m     queries: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m     88\u001b[0m     agg_fn: Optional[Callable[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     89\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[0;32m     90\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get aggregated embedding from multiple queries.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m     query_embeddings \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_query_embedding(query) \u001b[39mfor\u001b[39;00m query \u001b[39min\u001b[39;00m queries]\n\u001b[0;32m     92\u001b[0m     agg_fn \u001b[39m=\u001b[39m agg_fn \u001b[39mor\u001b[39;00m mean_agg\n\u001b[0;32m     93\u001b[0m     \u001b[39mreturn\u001b[39;00m agg_fn(query_embeddings)\n",
            "File \u001b[1;32mc:\\Users\\sherw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\embeddings\\base.py:77\u001b[0m, in \u001b[0;36mBaseEmbedding.get_query_embedding\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get query embedding.\"\"\"\u001b[39;00m\n\u001b[0;32m     76\u001b[0m event_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_event_start(CBEventType\u001b[39m.\u001b[39mEMBEDDING)\n\u001b[1;32m---> 77\u001b[0m query_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_query_embedding(query)\n\u001b[0;32m     78\u001b[0m query_tokens_count \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokenizer(query))\n\u001b[0;32m     79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_total_tokens_used \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m query_tokens_count\n",
            "File \u001b[1;32mc:\\Users\\sherw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\embeddings\\openai.py:235\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_query_embedding\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_query_embedding\u001b[39m(\u001b[39mself\u001b[39m, query: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[0;32m    234\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get query embedding.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m     \u001b[39mreturn\u001b[39;00m get_embedding(\n\u001b[0;32m    236\u001b[0m         query,\n\u001b[0;32m    237\u001b[0m         engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery_engine,\n\u001b[0;32m    238\u001b[0m         deployment_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment_name,\n\u001b[0;32m    239\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopenai_kwargs,\n\u001b[0;32m    240\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\sherw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
            "File \u001b[1;32mc:\\Users\\sherw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoSleep):\n\u001b[0;32m    388\u001b[0m     retry_state\u001b[39m.\u001b[39mprepare_for_next_attempt()\n\u001b[1;32m--> 389\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msleep(do)\n\u001b[0;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m do\n",
            "File \u001b[1;32mc:\\Users\\sherw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[1;34m(seconds)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msleep\u001b[39m(seconds: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[39m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     time\u001b[39m.\u001b[39;49msleep(seconds)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "ask_ai()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3PLMi_vAg7d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
